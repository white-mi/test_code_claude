{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Комплексное тестирование библиотеки dynamic_refitting\n",
    "\n",
    "**Цель:** пошаговая проверка всех модулей библиотеки на крупном внешнем датасете с замерами производительности и проверками корректности.\n",
    "\n",
    "**Датасет:** [Adult (Census Income)](https://www.openml.org/d/1590) — 48 842 записи, бинарная классификация (доход >50K), смесь числовых и категориальных признаков.\n",
    "\n",
    "### Содержание\n",
    "1. Загрузка данных и подготовка\n",
    "2. Модуль метрик ()\n",
    "3. Шаги валидации ()\n",
    "4. Feature Engineering ()\n",
    "5. AutoPipeBoost (LightGBM + Optuna)\n",
    "6. AutoPipeLogreg (Logistic Regression)\n",
    "7. Мониторинг дрифта ()\n",
    "8. Динамический рефиттинг ()\n",
    "9. Объясняемость ()\n",
    "10. Model Registry и ExperimentTracker\n",
    "11. Plugin Architecture ()\n",
    "12. Сериализация (save / load)\n",
    "13. Сводная таблица по времени"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ── timing infrastructure ───────────────────────────────────\n",
    "TIMING: dict = {}\n",
    "\n",
    "@contextmanager\n",
    "def timer(label: str):\n",
    "    \"\"\"Context-manager for measuring wall-clock time.\"\"\"\n",
    "    t0 = time.perf_counter()\n",
    "    yield\n",
    "    elapsed = time.perf_counter() - t0\n",
    "    TIMING[label] = elapsed\n",
    "    print(f\"⏱  {label}: {elapsed:.2f} s\")\n",
    "\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка внешнего датасета и подготовка данных\n",
    "\n",
    "Загружаем датасет **Adult / Census Income** через .\n",
    "Он содержит ~48 000 строк, 14 признаков (числовые + категориальные) и бинарную цель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "with timer(\"1. Загрузка датасета (fetch_openml)\"):\n",
    "    data = fetch_openml(\"adult\", version=2, as_frame=True, parser=\"auto\")\n",
    "    df_raw = data.data.copy()\n",
    "    # target → binary 0/1\n",
    "    df_raw[\"target\"] = (data.target.astype(str).str.strip().str.replace(\".\", \"\", regex=False) == \">50K\").astype(int)\n",
    "\n",
    "print(f\"Размер: {df_raw.shape}\")\n",
    "print(f\"Доля target=1: {df_raw['target'].mean():.3f}\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем синтетический столбец даты (12 месяцев) — нужен для time-based логики\n",
    "rng = np.random.RandomState(42)\n",
    "dates = pd.date_range(\"2023-01-01\", periods=12, freq=\"MS\")\n",
    "df_raw[\"date\"] = rng.choice(dates, size=len(df_raw))\n",
    "\n",
    "# Разбивка: train (первые 8 мес.) / test (9-10) / monitor (11-12)\n",
    "sorted_dates = sorted(dates)\n",
    "train_dates = set(sorted_dates[:8])\n",
    "test_dates  = set(sorted_dates[8:10])\n",
    "mon_dates   = set(sorted_dates[10:])\n",
    "\n",
    "df_train   = df_raw[df_raw[\"date\"].isin(train_dates)].reset_index(drop=True)\n",
    "df_test    = df_raw[df_raw[\"date\"].isin(test_dates)].reset_index(drop=True)\n",
    "df_monitor = df_raw[df_raw[\"date\"].isin(mon_dates)].reset_index(drop=True)\n",
    "\n",
    "X_train, y_train = df_train.drop(columns=[\"target\"]), df_train[\"target\"]\n",
    "X_test,  y_test  = df_test.drop(columns=[\"target\"]),  df_test[\"target\"]\n",
    "X_mon,   y_mon   = df_monitor.drop(columns=[\"target\"]), df_monitor[\"target\"]\n",
    "\n",
    "print(f\"Train: {len(df_train):,}  |  Test: {len(df_test):,}  |  Monitor: {len(df_monitor):,}\")\n",
    "print(f\"Train target rate: {y_train.mean():.3f}\")\n",
    "print(f\"Числовые: {X_train.select_dtypes(include=[np.number]).shape[1]}\")\n",
    "print(f\"Категориальные: {X_train.select_dtypes(include=['object','category']).shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Модуль метрик ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.utils.metrics import (\n",
    "    calc_auc, calc_ks, calc_brier, calc_psi, calc_metrics,\n",
    ")\n",
    "\n",
    "# Создаём простые прогнозы для проверки метрик\n",
    "rng = np.random.RandomState(0)\n",
    "y_dummy   = y_test.values\n",
    "p_dummy   = rng.rand(len(y_dummy))\n",
    "ref_dummy = rng.rand(len(y_train))\n",
    "\n",
    "with timer(\"2. calc_metrics (AUC + KS + Brier + PSI)\"):\n",
    "    m = calc_metrics(y_dummy, p_dummy,\n",
    "                     metric_names=[\"auc\", \"ks\", \"brier\", \"psi\"],\n",
    "                     reference_scores=ref_dummy)\n",
    "\n",
    "# Проверки корректности\n",
    "assert \"auc\" in m and 0 <= m[\"auc\"] <= 1, \"AUC вне диапазона [0,1]\"\n",
    "assert \"ks\" in m and 0 <= m[\"ks\"] <= 1,   \"KS вне диапазона [0,1]\"\n",
    "assert \"brier\" in m and 0 <= m[\"brier\"] <= 1, \"Brier вне диапазона [0,1]\"\n",
    "assert \"psi\" in m and m[\"psi\"] >= 0,       \"PSI < 0\"\n",
    "\n",
    "print(\"Метрики:\", {k: round(v, 4) for k, v in m.items()})\n",
    "\n",
    "# Отдельная проверка PSI на идентичных распределениях → ≈ 0\n",
    "psi_same = calc_psi(ref_dummy, ref_dummy)\n",
    "assert psi_same < 0.01, f\"PSI одинаковых распределений слишком велик: {psi_same}\"\n",
    "print(f\"PSI(identical) = {psi_same:.6f}  ✓\")\n",
    "print(\"Все проверки метрик пройдены ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Шаги валидации данных ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.validation_steps import (\n",
    "    FeatureCleanerConst,\n",
    "    FeatureCleanerNan,\n",
    "    FeatureCleanerUnivariate,\n",
    "    HitrateChecker,\n",
    "    PopulationStabilityIndex,\n",
    "    WoEStabChecker,\n",
    ")\n",
    "\n",
    "# ── FeatureCleanerConst ─────────────────────────────────────\n",
    "with timer(\"3a. FeatureCleanerConst\"):\n",
    "    cleaner_const = FeatureCleanerConst()\n",
    "    cleaner_const.fit(X_train, y_train)\n",
    "    X_cc = cleaner_const.transform(X_train)\n",
    "\n",
    "print(f\"  Удалено константных: {len(cleaner_const.constant_cols_)}  →  {cleaner_const.constant_cols_}\")\n",
    "assert X_cc.shape[0] == X_train.shape[0], \"Число строк изменилось\"\n",
    "assert X_cc.shape[1] <= X_train.shape[1], \"Столбцов стало больше\"\n",
    "\n",
    "# ── FeatureCleanerNan ───────────────────────────────────────\n",
    "with timer(\"3b. FeatureCleanerNan\"):\n",
    "    cleaner_nan = FeatureCleanerNan(nan_threshold=0.5, fill_strategy=\"median\")\n",
    "    cleaner_nan.fit(X_cc, y_train)\n",
    "    X_cn = cleaner_nan.transform(X_cc)\n",
    "\n",
    "print(f\"  Удалено (>50% NaN): {len(cleaner_nan.drop_cols_)}  |  Заполнено: {len(cleaner_nan._fill_values)}\")\n",
    "num_nans_after = X_cn.select_dtypes(include=[np.number]).isna().sum().sum()\n",
    "print(f\"  NaN в числовых после обработки: {num_nans_after}\")\n",
    "\n",
    "# ── FeatureCleanerUnivariate ────────────────────────────────\n",
    "with timer(\"3c. FeatureCleanerUnivariate\"):\n",
    "    cleaner_uni = FeatureCleanerUnivariate(min_auc=0.52)\n",
    "    cleaner_uni.fit(X_cn, y_train)\n",
    "    X_cu = cleaner_uni.transform(X_cn)\n",
    "\n",
    "print(f\"  Отобрано признаков: {len(cleaner_uni.selected_features_)} / {len(cleaner_uni.feature_aucs_)}\")\n",
    "assert len(cleaner_uni.selected_features_) > 0, \"Ни один признак не прошёл фильтр\"\n",
    "\n",
    "# ── HitrateChecker ──────────────────────────────────────────\n",
    "with timer(\"3d. HitrateChecker\"):\n",
    "    hr = HitrateChecker(min_rate=0.01, max_rate=0.5)\n",
    "    hr.fit(X_cn, y_train)\n",
    "\n",
    "print(f\"  Event rate: {hr.actual_rate_:.4f}\")\n",
    "assert hr.actual_rate_ > 0, \"Event rate = 0\"\n",
    "\n",
    "# ── PopulationStabilityIndex ────────────────────────────────\n",
    "with timer(\"3e. PopulationStabilityIndex\"):\n",
    "    psi_step = PopulationStabilityIndex(n_bins=10, threshold=0.25)\n",
    "    psi_step.fit(X_cn)\n",
    "    psi_step.transform(X_test.reindex(columns=X_cn.columns, fill_value=0))\n",
    "\n",
    "n_high = sum(1 for v in psi_step.psi_values_.values() if v > 0.25)\n",
    "print(f\"  Проверено фичей: {len(psi_step.psi_values_)}  |  Высокий PSI: {n_high}\")\n",
    "\n",
    "# ── WoEStabChecker ──────────────────────────────────────────\n",
    "with timer(\"3f. WoEStabChecker\"):\n",
    "    woe_stab = WoEStabChecker(time_col=\"date\", target_col=\"target\", psi_threshold=0.25)\n",
    "    df_for_stab = X_cn.copy()\n",
    "    df_for_stab[\"date\"] = df_train[\"date\"].values\n",
    "    woe_stab.fit(df_for_stab, y_train)\n",
    "\n",
    "print(f\"  Фичей в отчёте: {len(woe_stab.stability_report_)}\")\n",
    "print(\"Все проверки валидации пройдены ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.feature_engineering import (\n",
    "    TargetEncoderCV,\n",
    "    FrequencyEncoder,\n",
    "    CategoryEmbedder,\n",
    "    InteractionGenerator,\n",
    "    DatetimeFeatures,\n",
    "    LagFeatureGenerator,\n",
    "    RollingStatGenerator,\n",
    ")\n",
    "\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# ── TargetEncoderCV ─────────────────────────────────────────\n",
    "with timer(\"4a. TargetEncoderCV fit_transform\"):\n",
    "    te = TargetEncoderCV(cols=cat_cols, n_folds=5, smoothing=10.0)\n",
    "    X_te = te.fit_transform(X_train.copy(), y_train)\n",
    "\n",
    "assert X_te[cat_cols].dtypes.apply(lambda d: np.issubdtype(d, np.floating)).all(),     \"Не все кат. столбцы стали float\"\n",
    "print(f\"  Кодировано {len(cat_cols)} категориальных столбцов\")\n",
    "\n",
    "# ── FrequencyEncoder ────────────────────────────────────────\n",
    "with timer(\"4b. FrequencyEncoder\"):\n",
    "    fe = FrequencyEncoder(cols=cat_cols, normalize=True)\n",
    "    fe.fit(X_train, y_train)\n",
    "    X_fe = fe.transform(X_train.copy())\n",
    "\n",
    "assert X_fe[cat_cols].max().max() <= 1.0, \"Нормализованные частоты > 1\"\n",
    "print(f\"  Кодировано {len(fe._freq_map)} столбцов\")\n",
    "\n",
    "# ── CategoryEmbedder ────────────────────────────────────────\n",
    "with timer(\"4c. CategoryEmbedder\"):\n",
    "    ce = CategoryEmbedder(cols=cat_cols)\n",
    "    ce.fit(X_train)\n",
    "    X_ce = ce.transform(X_train.copy())\n",
    "\n",
    "assert X_ce[cat_cols].dtypes.apply(lambda d: np.issubdtype(d, np.integer)).all(),     \"Не все столбцы стали int\"\n",
    "print(f\"  Кодировано {len(ce._mapping)} столбцов\")\n",
    "\n",
    "# ── InteractionGenerator ────────────────────────────────────\n",
    "with timer(\"4d. InteractionGenerator\"):\n",
    "    ig = InteractionGenerator(cols=num_cols[:5], max_pairs=10, interaction_type=\"multiply\")\n",
    "    ig.fit(X_train)\n",
    "    X_ig = ig.transform(X_train.copy())\n",
    "\n",
    "new_int_cols = [c for c in X_ig.columns if \"_x_\" in c]\n",
    "print(f\"  Создано интеракций: {len(new_int_cols)}\")\n",
    "assert len(new_int_cols) == len(ig._pairs), \"Число интеракций не совпадает\"\n",
    "\n",
    "# ── DatetimeFeatures ────────────────────────────────────────\n",
    "with timer(\"4e. DatetimeFeatures\"):\n",
    "    dtf = DatetimeFeatures(datetime_col=\"date\", features=[\"month\", \"dayofweek\", \"quarter\"])\n",
    "    dtf.fit(X_train)\n",
    "    X_dt = dtf.transform(X_train.copy())\n",
    "\n",
    "assert \"date_month\" in X_dt.columns, \"date_month не создан\"\n",
    "assert \"date_quarter\" in X_dt.columns, \"date_quarter не создан\"\n",
    "print(f\"  Создано dt-признаков: {sum(1 for c in X_dt.columns if c.startswith('date_'))}\")\n",
    "\n",
    "# ── LagFeatureGenerator ─────────────────────────────────────\n",
    "with timer(\"4f. LagFeatureGenerator\"):\n",
    "    lfg = LagFeatureGenerator(lag_cols=num_cols[:3], lags=[1, 3], sort_col=\"date\")\n",
    "    lfg.fit(X_train)\n",
    "    X_lag = lfg.transform(X_train.copy())\n",
    "\n",
    "lag_cols_created = [c for c in X_lag.columns if \"_lag\" in c]\n",
    "print(f\"  Создано лаговых признаков: {len(lag_cols_created)}\")\n",
    "assert len(lag_cols_created) == 3 * 2, \"Ожидалось 6 лаговых признаков\"\n",
    "\n",
    "# ── RollingStatGenerator ────────────────────────────────────\n",
    "with timer(\"4g. RollingStatGenerator\"):\n",
    "    rsg = RollingStatGenerator(\n",
    "        stat_cols=num_cols[:2], windows=[3, 5], funcs=[\"mean\", \"std\"], sort_col=\"date\"\n",
    "    )\n",
    "    rsg.fit(X_train)\n",
    "    X_roll = rsg.transform(X_train.copy())\n",
    "\n",
    "roll_cols = [c for c in X_roll.columns if \"_roll\" in c]\n",
    "print(f\"  Создано rolling-признаков: {len(roll_cols)}\")\n",
    "assert len(roll_cols) == 2 * 2 * 2, \"Ожидалось 8 rolling-признаков\"\n",
    "\n",
    "print(\"Все проверки Feature Engineering пройдены ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. AutoPipeBoost (LightGBM + Optuna)\n",
    "\n",
    "Обучение полного бустингового пайплайна: очистка → предселекция → корреляции → хвосты → Optuna-LightGBM.\n",
    "Используем  и  для ускорения теста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.config import PipelineConfig\n",
    "from dynamic_refitting.autopipe import AutoPipeBoost\n",
    "\n",
    "config_boost = PipelineConfig(\n",
    "    random_state=42,\n",
    "    target_col=\"target\",\n",
    "    time_col=\"date\",\n",
    "    metrics=[\"auc\", \"ks\", \"brier\"],\n",
    ")\n",
    "\n",
    "pipe_boost = AutoPipeBoost(config=config_boost, optuna_n_trials=10)\n",
    "\n",
    "with timer(\"5. AutoPipeBoost.fit (10 Optuna trials, 3-fold CV)\"):\n",
    "    pipe_boost.fit(X_train, y_train, run_cv=True, n_splits=3)\n",
    "\n",
    "# ── Проверки ────────────────────────────────────────────────\n",
    "assert pipe_boost.pipeline_ is not None, \"Pipeline не создан\"\n",
    "assert pipe_boost.pipeline_._fitted, \"Pipeline не обучен\"\n",
    "assert \"auc\" in pipe_boost.train_metrics_, \"AUC не посчитан\"\n",
    "assert pipe_boost.train_metrics_[\"auc\"] > 0.5, \"Train AUC <= 0.5\"\n",
    "assert len(pipe_boost.cv_results_) == 3, \"CV results не 3 фолда\"\n",
    "\n",
    "print(f\"Train metrics: { {k: round(v, 4) for k, v in pipe_boost.train_metrics_.items()} }\")\n",
    "cv_aucs = [r[\"auc\"] for r in pipe_boost.cv_results_]\n",
    "print(f\"CV AUCs: {[round(a, 4) for a in cv_aucs]}\")\n",
    "print(f\"CV AUC mean: {np.mean(cv_aucs):.4f}  std: {np.std(cv_aucs):.4f}\")\n",
    "\n",
    "# Предсказание на тесте\n",
    "with timer(\"5b. AutoPipeBoost.predict_proba (test)\"):\n",
    "    proba_boost_test = pipe_boost.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_auc_boost = calc_auc(y_test.values, proba_boost_test)\n",
    "test_ks_boost  = calc_ks(y_test.values, proba_boost_test)\n",
    "assert test_auc_boost > 0.5, f\"Test AUC={test_auc_boost:.4f} <= 0.5\"\n",
    "print(f\"Test AUC: {test_auc_boost:.4f}  |  KS: {test_ks_boost:.4f}\")\n",
    "print(\"AutoPipeBoost ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. AutoPipeLogreg (Logistic Regression)\n",
    "\n",
    "WoE-кодирование, монотонный биннинг, StandardScaler, LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.autopipe import AutoPipeLogreg\n",
    "\n",
    "config_lr = PipelineConfig(\n",
    "    random_state=42,\n",
    "    target_col=\"target\",\n",
    "    time_col=\"date\",\n",
    "    metrics=[\"auc\", \"ks\", \"brier\"],\n",
    ")\n",
    "\n",
    "pipe_lr = AutoPipeLogreg(config=config_lr, C=1.0, penalty=\"l2\")\n",
    "\n",
    "with timer(\"6. AutoPipeLogreg.fit (3-fold CV)\"):\n",
    "    pipe_lr.fit(X_train, y_train, run_cv=True, n_splits=3)\n",
    "\n",
    "assert pipe_lr.pipeline_ is not None, \"Pipeline не создан\"\n",
    "assert pipe_lr.train_metrics_[\"auc\"] > 0.5, \"Train AUC <= 0.5\"\n",
    "\n",
    "print(f\"Train metrics: { {k: round(v, 4) for k, v in pipe_lr.train_metrics_.items()} }\")\n",
    "cv_aucs_lr = [r[\"auc\"] for r in pipe_lr.cv_results_]\n",
    "print(f\"CV AUCs: {[round(a, 4) for a in cv_aucs_lr]}\")\n",
    "print(f\"CV AUC mean: {np.mean(cv_aucs_lr):.4f}\")\n",
    "\n",
    "with timer(\"6b. AutoPipeLogreg.predict_proba (test)\"):\n",
    "    proba_lr_test = pipe_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "test_auc_lr = calc_auc(y_test.values, proba_lr_test)\n",
    "test_ks_lr  = calc_ks(y_test.values, proba_lr_test)\n",
    "print(f\"Test AUC: {test_auc_lr:.4f}  |  KS: {test_ks_lr:.4f}\")\n",
    "print(\"AutoPipeLogreg ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Мониторинг дрифта\n",
    "\n",
    "Тестируем , , , ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.monitoring import (\n",
    "    FeatureDriftDetector,\n",
    "    PredictionDriftMonitor,\n",
    "    ModelPerformanceMonitor,\n",
    "    DriftReportGenerator,\n",
    ")\n",
    "\n",
    "# ── FeatureDriftDetector ────────────────────────────────────\n",
    "with timer(\"7a. FeatureDriftDetector (fit + transform)\"):\n",
    "    drift_det = FeatureDriftDetector(psi_threshold=0.2, ks_threshold=0.05)\n",
    "    drift_det.fit(X_train)\n",
    "    drift_det.transform(X_mon)\n",
    "\n",
    "print(f\"  Проверено фичей: {len(drift_det.drift_report_)}\")\n",
    "print(f\"  Дрифтовых: {len(drift_det.drifted_features)}\")\n",
    "if drift_det.drifted_features:\n",
    "    print(f\"  Список: {drift_det.drifted_features[:5]}...\")\n",
    "\n",
    "# Проверяем формат отчёта\n",
    "for col, info in list(drift_det.drift_report_.items())[:1]:\n",
    "    assert \"psi\" in info and \"ks_stat\" in info and \"ks_pvalue\" in info and \"drifted\" in info,         \"Неполный drift_report\"\n",
    "    assert info[\"psi\"] >= 0, \"PSI < 0\"\n",
    "\n",
    "# ── PredictionDriftMonitor ──────────────────────────────────\n",
    "proba_train_boost = pipe_boost.predict_proba(X_train)[:, 1]\n",
    "proba_mon_boost   = pipe_boost.predict_proba(X_mon)[:, 1]\n",
    "\n",
    "with timer(\"7b. PredictionDriftMonitor\"):\n",
    "    pred_drift = PredictionDriftMonitor(psi_threshold=0.2)\n",
    "    pred_drift.fit(X_train, reference_scores=proba_train_boost)\n",
    "    check = pred_drift.check(proba_mon_boost)\n",
    "\n",
    "print(f\"  Prediction PSI: {check['psi']:.4f}  |  Drifted: {check['drifted']}\")\n",
    "assert \"psi\" in check and \"drifted\" in check, \"Неполный check\"\n",
    "\n",
    "# ── ModelPerformanceMonitor ─────────────────────────────────\n",
    "with timer(\"7c. ModelPerformanceMonitor\"):\n",
    "    perf_mon = ModelPerformanceMonitor(\n",
    "        time_col=\"date\", metrics=[\"auc\", \"ks\", \"brier\"], auc_threshold=0.6\n",
    "    )\n",
    "    perf_mon.fit(X_mon)\n",
    "    perf_results = perf_mon.evaluate(\n",
    "        y_test, proba_boost_test,\n",
    "        time_values=df_test[\"date\"]\n",
    "    )\n",
    "\n",
    "print(f\"  Периодов: {len(perf_results)}\")\n",
    "for r in perf_results[:3]:\n",
    "    print(f\"    {r['period']}: AUC={r.get('auc', 'N/A'):.4f}\")\n",
    "assert len(perf_mon.performance_history_) > 0, \"History пуст\"\n",
    "\n",
    "rolling_auc = perf_mon.get_rolling_auc(window=2)\n",
    "print(f\"  Rolling AUC (w=2): {[round(a, 4) for a in rolling_auc]}\")\n",
    "print(\"Monitoring ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── DriftReportGenerator ─────────────────────────────────────\n",
    "with timer(\"7d. DriftReportGenerator\"):\n",
    "    reporter = DriftReportGenerator()\n",
    "    reporter.fit(X_train)\n",
    "    report = reporter.generate(\n",
    "        feature_drift=drift_det,\n",
    "        prediction_drift=pred_drift,\n",
    "        performance_monitor=perf_mon,\n",
    "        metadata={\"dataset\": \"adult\", \"split\": \"monitor\"},\n",
    "    )\n",
    "\n",
    "assert \"timestamp\" in report, \"Нет timestamp\"\n",
    "assert \"feature_drift\" in report, \"Нет feature_drift\"\n",
    "assert \"prediction_drift\" in report, \"Нет prediction_drift\"\n",
    "assert \"performance\" in report, \"Нет performance\"\n",
    "assert \"summary\" in report, \"Нет summary\"\n",
    "\n",
    "print(f\"Needs refit: {report['summary']['needs_refit']}\")\n",
    "print(f\"Reasons: {report['summary']['reasons']}\")\n",
    "print(f\"Feature drift — total: {report['feature_drift']['total_features_checked']}, \"\n",
    "      f\"drifted: {report['feature_drift']['n_drifted']}\")\n",
    "print(\"DriftReportGenerator ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Динамический рефиттинг ()\n",
    "\n",
    "Тестируем триггеры (Performance / Time / DataVolume) и ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.refit import (\n",
    "    PerformanceTriggeredRefit,\n",
    "    TimeBasedRefit,\n",
    "    DataVolumeTriggeredRefit,\n",
    "    RefitManager,\n",
    "    RefitScheduler,\n",
    ")\n",
    "\n",
    "# ── PerformanceTriggeredRefit ───────────────────────────────\n",
    "with timer(\"8a. PerformanceTriggeredRefit\"):\n",
    "    perf_trig = PerformanceTriggeredRefit(auc_threshold=0.99, psi_threshold=0.01)\n",
    "    # Порог AUC=0.99 — любая реальная модель его не пройдёт → trigger fires\n",
    "    fired = perf_trig.should_refit(\n",
    "        y_true=y_test.values,\n",
    "        y_score=proba_boost_test,\n",
    "        reference_scores=proba_train_boost,\n",
    "    )\n",
    "\n",
    "print(f\"  Fired (AUC<0.99): {fired}  |  Reason: {perf_trig.get_reason()}\")\n",
    "assert fired, \"Trigger должен был сработать при AUC<0.99\"\n",
    "\n",
    "# Нормальный порог — не должен сработать\n",
    "perf_trig2 = PerformanceTriggeredRefit(auc_threshold=0.5, psi_threshold=10.0)\n",
    "fired2 = perf_trig2.should_refit(\n",
    "    y_true=y_test.values, y_score=proba_boost_test, reference_scores=proba_train_boost,\n",
    ")\n",
    "print(f\"  Fired (AUC<0.5): {fired2}  → ожидаем False\")\n",
    "assert not fired2, \"Trigger не должен был сработать при AUC<0.5\"\n",
    "\n",
    "# ── TimeBasedRefit ──────────────────────────────────────────\n",
    "with timer(\"8b. TimeBasedRefit\"):\n",
    "    time_trig = TimeBasedRefit(interval_days=0)  # 0 дней → сразу fire\n",
    "    fired_t = time_trig.should_refit()\n",
    "\n",
    "print(f\"  Fired (0 days): {fired_t}\")\n",
    "assert fired_t, \"TimeBasedRefit(0 days) должен сработать\"\n",
    "\n",
    "time_trig.reset()\n",
    "time_trig2 = TimeBasedRefit(interval_days=999)\n",
    "assert not time_trig2.should_refit(), \"999 days не должен сработать сразу\"\n",
    "print(\"  TimeBasedRefit(999 days): False ✓\")\n",
    "\n",
    "# ── DataVolumeTriggeredRefit ────────────────────────────────\n",
    "with timer(\"8c. DataVolumeTriggeredRefit\"):\n",
    "    vol_trig = DataVolumeTriggeredRefit(min_new_samples=100)\n",
    "    assert not vol_trig.should_refit(), \"Не должен сработать без данных\"\n",
    "    vol_trig.add_samples(50)\n",
    "    assert not vol_trig.should_refit(), \"50 < 100\"\n",
    "    vol_trig.add_samples(60)\n",
    "    assert vol_trig.should_refit(), \"110 >= 100, должен сработать\"\n",
    "    vol_trig.reset()\n",
    "    assert not vol_trig.should_refit(), \"После reset не должен\"\n",
    "\n",
    "print(\"  DataVolumeTriggeredRefit ✓\")\n",
    "print(\"Все триггеры пройдены ✓\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── RefitManager ─────────────────────────────────────────────\n",
    "triggers = [\n",
    "    PerformanceTriggeredRefit(auc_threshold=0.99, psi_threshold=0.01),\n",
    "    DataVolumeTriggeredRefit(min_new_samples=10),\n",
    "]\n",
    "triggers[1].add_samples(1000)  # наполняем триггер\n",
    "\n",
    "assert pipe_boost.pipeline_ is not None\n",
    "manager = RefitManager(\n",
    "    pipeline=pipe_boost.pipeline_,\n",
    "    triggers=triggers,\n",
    "    config=config_boost,\n",
    ")\n",
    "manager.set_reference_scores(proba_train_boost)\n",
    "\n",
    "# check_triggers → должен вернуть причины\n",
    "reasons = manager.check_triggers(\n",
    "    y_true=y_test.values,\n",
    "    y_score=proba_boost_test,\n",
    ")\n",
    "print(f\"Reasons: {reasons}\")\n",
    "assert len(reasons) > 0, \"Должны быть причины для рефита\"\n",
    "\n",
    "# Выполняем ручной refit\n",
    "with timer(\"8d. RefitManager.refit\"):\n",
    "    refitted = manager.refit(X_train, y_train)\n",
    "\n",
    "assert refitted is not None, \"refit вернул None\"\n",
    "assert len(manager.refit_history_) == 1, \"History не обновлён\"\n",
    "rec = manager.refit_history_[0]\n",
    "print(f\"  Refit: {rec['n_samples']} samples, {rec['elapsed_seconds']:.2f}s\")\n",
    "print(f\"  Metrics after refit: { {k: round(v, 4) for k, v in rec['metrics'].items()} }\")\n",
    "\n",
    "# auto_refit с низким порогом → должен сработать\n",
    "triggers2 = [PerformanceTriggeredRefit(auc_threshold=0.99, psi_threshold=0.01)]\n",
    "manager2 = RefitManager(pipeline=pipe_boost.pipeline_, triggers=triggers2, config=config_boost)\n",
    "manager2.set_reference_scores(proba_train_boost)\n",
    "\n",
    "with timer(\"8e. RefitManager.auto_refit\"):\n",
    "    result = manager2.auto_refit(\n",
    "        X_monitor=X_test, y_monitor=y_test,\n",
    "        X_train=X_train, y_train=y_train,\n",
    "    )\n",
    "\n",
    "assert result is not None, \"auto_refit должен был сработать\"\n",
    "print(f\"  auto_refit: {len(manager2.refit_history_)} записей в истории\")\n",
    "\n",
    "# ── RefitScheduler ──────────────────────────────────────────\n",
    "with timer(\"8f. RefitScheduler\"):\n",
    "    scheduler = RefitScheduler(check_interval_seconds=0, max_checks=3)\n",
    "    call_count = 0\n",
    "    def cb():\n",
    "        global call_count\n",
    "        call_count += 1\n",
    "        return call_count == 2  # refit на втором вызове\n",
    "    scheduler.register_callback(cb)\n",
    "    scheduler.run()\n",
    "\n",
    "assert len(scheduler.history_) == 3, f\"Ожидалось 3 проверки, получено {len(scheduler.history_)}\"\n",
    "assert scheduler.history_[1][\"refit_triggered\"], \"Второй вызов должен был trigger\"\n",
    "print(f\"  Scheduler: {len(scheduler.history_)} checks done\")\n",
    "print(\"RefitManager + Scheduler ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Объясняемость ()\n",
    "\n",
    ", , , ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.explainability import (\n",
    "    PermutationImportance,\n",
    "    PartialDependence,\n",
    "    CounterfactualGenerator,\n",
    "    ModelCardGenerator,\n",
    ")\n",
    "\n",
    "# Достаём обученную LightGBM-модель из пайплайна\n",
    "lgb_step = pipe_boost.pipeline_.estimator\n",
    "lgb_model = lgb_step.model_\n",
    "feat_names = lgb_step._feature_names\n",
    "\n",
    "# Готовим числовой X для explainability\n",
    "X_test_transformed = pipe_boost.pipeline_.transform(X_test)\n",
    "X_test_num = X_test_transformed[feat_names].fillna(0)\n",
    "\n",
    "# ── PermutationImportance ───────────────────────────────────\n",
    "with timer(\"9a. PermutationImportance (5 repeats)\"):\n",
    "    perm_imp = PermutationImportance(n_repeats=5, scoring=\"roc_auc\")\n",
    "    perm_imp.fit(X_test_transformed, y=y_test, model=lgb_model)\n",
    "\n",
    "top5 = perm_imp.get_top_features(5)\n",
    "print(f\"  Top-5 features: {top5}\")\n",
    "assert len(top5) == 5, \"Ожидалось 5 фичей\"\n",
    "assert perm_imp.importances_ is not None\n",
    "assert perm_imp.importances_[\"mean\"].iloc[0] >= 0, \"Top importance < 0\"\n",
    "\n",
    "# ── PartialDependence ───────────────────────────────────────\n",
    "pdp_features = feat_names[:3]  # первые 3 фичи\n",
    "with timer(\"9b. PartialDependence (3 features, grid=30)\"):\n",
    "    pdp = PartialDependence(features=pdp_features, grid_resolution=30)\n",
    "    pdp.fit(X_test_transformed, model=lgb_model)\n",
    "\n",
    "assert len(pdp.pdp_results_) > 0, \"PDP пуст\"\n",
    "for feat, res in pdp.pdp_results_.items():\n",
    "    assert \"grid\" in res and \"avg_prediction\" in res\n",
    "    assert len(res[\"grid\"]) == 30\n",
    "    print(f\"  PDP {feat}: pred range [{res['avg_prediction'].min():.4f}, {res['avg_prediction'].max():.4f}]\")\n",
    "\n",
    "# ── CounterfactualGenerator ─────────────────────────────────\n",
    "with timer(\"9c. CounterfactualGenerator\"):\n",
    "    cf_gen = CounterfactualGenerator(target_class=0, max_features_to_change=5, step_size=0.5, max_iterations=50)\n",
    "    cf_gen.fit(X_test_transformed, model=lgb_model)\n",
    "    instance = X_test_num.iloc[0]\n",
    "    cf_result = cf_gen.explain(instance, feature_names=feat_names[:5])\n",
    "\n",
    "print(f\"  Counterfactual success: {cf_result['success']}\")\n",
    "print(f\"  Changes: {len(cf_result['changes'])} features modified\")\n",
    "assert \"success\" in cf_result and \"changes\" in cf_result\n",
    "\n",
    "# ── ModelCardGenerator ──────────────────────────────────────\n",
    "with timer(\"9d. ModelCardGenerator\"):\n",
    "    mcg = ModelCardGenerator(model_name=\"BoostModel_Adult\", model_version=\"1.0\")\n",
    "    mcg.fit(X_train)\n",
    "    card = mcg.generate(\n",
    "        model_type=\"LightGBM\",\n",
    "        features=feat_names,\n",
    "        training_metrics=pipe_boost.train_metrics_,\n",
    "        validation_metrics={\"auc\": test_auc_boost, \"ks\": test_ks_boost},\n",
    "        dataset_description=\"Adult Census Income, 48K rows\",\n",
    "        intended_use=\"Binary classification (income >50K)\",\n",
    "    )\n",
    "\n",
    "assert \"model_details\" in card and \"metrics\" in card\n",
    "print(f\"  Model card: {card['model_details']['name']} v{card['model_details']['version']}\")\n",
    "print(f\"  Features: {card['model_details']['n_features']}\")\n",
    "print(\"Explainability ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Model Registry и ExperimentTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.registry import ModelRegistry\n",
    "from dynamic_refitting.registry.experiment_tracker import ExperimentTracker\n",
    "\n",
    "tmp_dir = tempfile.mkdtemp(prefix=\"dr_test_\")\n",
    "\n",
    "# ── ModelRegistry ───────────────────────────────────────────\n",
    "with timer(\"10a. ModelRegistry (register + promote + rollback)\"):\n",
    "    registry = ModelRegistry(root_dir=Path(tmp_dir) / \"registry\")\n",
    "\n",
    "    mv1 = registry.register(\n",
    "        \"scoring_adult\", pipe_boost.pipeline_,\n",
    "        metrics={\"auc\": test_auc_boost}, tags={\"env\": \"test\"},\n",
    "    )\n",
    "    assert mv1.version == 1\n",
    "    assert mv1.stage == \"staging\"\n",
    "\n",
    "    registry.promote(\"scoring_adult\", version=1)\n",
    "    prod = registry.get_production(\"scoring_adult\")\n",
    "    assert prod is not None and prod.version == 1\n",
    "\n",
    "    mv2 = registry.register(\n",
    "        \"scoring_adult\", pipe_lr.pipeline_,\n",
    "        metrics={\"auc\": test_auc_lr}, tags={\"env\": \"test\"},\n",
    "    )\n",
    "    assert mv2.version == 2\n",
    "    registry.promote(\"scoring_adult\", version=2)\n",
    "    assert registry.get_production(\"scoring_adult\").version == 2\n",
    "    assert registry.get_version(\"scoring_adult\", 1).stage == \"archived\"\n",
    "\n",
    "    # Rollback\n",
    "    prev = registry.rollback(\"scoring_adult\")\n",
    "    assert prev is not None and prev.version == 1\n",
    "    assert prev.stage == \"production\"\n",
    "\n",
    "    # Load model\n",
    "    loaded = registry.load_model(\"scoring_adult\")\n",
    "    assert loaded is not None\n",
    "\n",
    "    # Tags\n",
    "    registry.tag(\"scoring_adult\", version=1, tags={\"team\": \"risk\"})\n",
    "    v1 = registry.get_version(\"scoring_adult\", 1)\n",
    "    assert v1.tags[\"team\"] == \"risk\"\n",
    "\n",
    "    versions = registry.list_versions(\"scoring_adult\")\n",
    "    assert len(versions) == 2\n",
    "\n",
    "print(f\"  Versions: {[(v.version, v.stage) for v in versions]}\")\n",
    "print(\"ModelRegistry ✓\")\n",
    "\n",
    "# ── ExperimentTracker ───────────────────────────────────────\n",
    "with timer(\"10b. ExperimentTracker\"):\n",
    "    tracker = ExperimentTracker(storage_dir=Path(tmp_dir) / \"experiments\")\n",
    "    run = tracker.start_run(\n",
    "        \"boost_test\",\n",
    "        params={\"n_trials\": 10, \"n_splits\": 3},\n",
    "        tags={\"dataset\": \"adult\"},\n",
    "    )\n",
    "    tracker.log_metrics(run.run_id, {\"auc\": test_auc_boost, \"ks\": test_ks_boost})\n",
    "    tracker.end_run(run.run_id, status=\"completed\")\n",
    "\n",
    "    loaded_run = tracker.get_run(run.run_id)\n",
    "    assert loaded_run.status == \"completed\"\n",
    "    assert loaded_run.metrics[\"auc\"] == test_auc_boost\n",
    "\n",
    "    runs = tracker.list_runs(\"boost_test\")\n",
    "    assert len(runs) >= 1\n",
    "\n",
    "print(f\"  Run: {loaded_run.run_id}, status={loaded_run.status}\")\n",
    "print(f\"  Metrics: {loaded_run.metrics}\")\n",
    "print(\"ExperimentTracker ✓\")\n",
    "\n",
    "# Cleanup\n",
    "shutil.rmtree(tmp_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Plugin Architecture ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.registry import StepRegistry\n",
    "from dynamic_refitting.config import BaseStep\n",
    "\n",
    "with timer(\"11. StepRegistry\"):\n",
    "    StepRegistry.clear()  # чистим для теста\n",
    "\n",
    "    # Определяем кастомный шаг\n",
    "    class MyCustomStep(BaseStep):\n",
    "        def fit(self, X, y=None, **kw):\n",
    "            self._fitted = True\n",
    "            return self\n",
    "        def transform(self, X):\n",
    "            return X\n",
    "\n",
    "    # Регистрируем\n",
    "    StepRegistry.register(\"custom\", \"my_step\", MyCustomStep)\n",
    "    assert \"custom\" in StepRegistry.list_categories()\n",
    "    assert \"my_step\" in StepRegistry.list_steps(\"custom\")\n",
    "\n",
    "    # Получаем и создаём экземпляр\n",
    "    cls = StepRegistry.get(\"custom\", \"my_step\")\n",
    "    assert cls is MyCustomStep\n",
    "    step = cls(random_state=42)\n",
    "    step.fit(X_train)\n",
    "    X_out = step.transform(X_train)\n",
    "    assert X_out.shape == X_train.shape, \"Custom step изменил shape\"\n",
    "\n",
    "    # Повторная регистрация без overwrite → ошибка\n",
    "    try:\n",
    "        StepRegistry.register(\"custom\", \"my_step\", MyCustomStep)\n",
    "        assert False, \"Должна была быть ошибка\"\n",
    "    except KeyError:\n",
    "        pass  # ожидаемо\n",
    "\n",
    "    # С overwrite → ОК\n",
    "    StepRegistry.register(\"custom\", \"my_step\", MyCustomStep, overwrite=True)\n",
    "\n",
    "    StepRegistry.clear()\n",
    "    assert len(StepRegistry.list_categories()) == 0\n",
    "\n",
    "print(\"StepRegistry ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Сериализация (save / load)\n",
    "\n",
    "Проверяем сохранение и загрузку PipelineConfig и ScoringPipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.config import ScoringPipeline\n",
    "\n",
    "tmp_dir = tempfile.mkdtemp(prefix=\"dr_serial_\")\n",
    "\n",
    "with timer(\"12a. Save/Load PipelineConfig\"):\n",
    "    cfg_path = Path(tmp_dir) / \"config.json\"\n",
    "    config_boost.save(cfg_path)\n",
    "    loaded_cfg = PipelineConfig.load(cfg_path)\n",
    "    assert loaded_cfg.random_state == config_boost.random_state\n",
    "    assert loaded_cfg.target_col == config_boost.target_col\n",
    "    assert loaded_cfg.metrics == config_boost.metrics\n",
    "\n",
    "print(f\"  Config saved/loaded: random_state={loaded_cfg.random_state}, metrics={loaded_cfg.metrics}\")\n",
    "\n",
    "with timer(\"12b. Save/Load ScoringPipeline (boost)\"):\n",
    "    pipe_path = Path(tmp_dir) / \"boost_pipe.joblib\"\n",
    "    pipe_boost.pipeline_.save(pipe_path)\n",
    "    loaded_pipe = ScoringPipeline.load(pipe_path)\n",
    "\n",
    "# Предсказываем загруженным пайплайном\n",
    "with timer(\"12c. Predict from loaded pipeline\"):\n",
    "    proba_loaded = loaded_pipe.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Проверяем что предсказания идентичны\n",
    "assert np.allclose(proba_loaded, proba_boost_test, atol=1e-6),     \"Предсказания загруженного пайплайна отличаются!\"\n",
    "print(f\"  Predictions match: max diff = {np.max(np.abs(proba_loaded - proba_boost_test)):.2e}\")\n",
    "\n",
    "with timer(\"12d. Save/Load ScoringPipeline (logreg)\"):\n",
    "    lr_path = Path(tmp_dir) / \"lr_pipe.joblib\"\n",
    "    pipe_lr.pipeline_.save(lr_path)\n",
    "    loaded_lr = ScoringPipeline.load(lr_path)\n",
    "    proba_lr_loaded = loaded_lr.predict_proba(X_test)[:, 1]\n",
    "    assert np.allclose(proba_lr_loaded, proba_lr_test, atol=1e-6)\n",
    "\n",
    "print(f\"  LR predictions match ✓\")\n",
    "print(\"Serialization ✓\")\n",
    "\n",
    "shutil.rmtree(tmp_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Custom Pipeline (ручная сборка)\n",
    "\n",
    "Собираем пайплайн вручную через  и проверяем работу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.config import ScoringPipeline\n",
    "from dynamic_refitting.validation_steps import FeatureCleanerConst, FeatureCleanerNan\n",
    "from dynamic_refitting.boost_pipeline_steps import (\n",
    "    FeaturePreSelector,\n",
    "    ClearCorrelatedFeatures,\n",
    "    ClearTailFeatures,\n",
    "    OptunaBoostingFitter,\n",
    ")\n",
    "\n",
    "custom_steps = [\n",
    "    FeatureCleanerConst(random_state=42),\n",
    "    FeatureCleanerNan(random_state=42, fill_strategy=\"median\"),\n",
    "    FeaturePreSelector(random_state=42, nan_threshold=0.8),\n",
    "    ClearCorrelatedFeatures(random_state=42, threshold=0.95),\n",
    "    ClearTailFeatures(random_state=42),\n",
    "    OptunaBoostingFitter(n_trials=5, random_state=42, time_col=\"date\"),\n",
    "]\n",
    "\n",
    "custom_pipe = ScoringPipeline(steps=custom_steps, config=config_boost)\n",
    "\n",
    "with timer(\"13. Custom ScoringPipeline.fit (5 Optuna trials)\"):\n",
    "    custom_pipe.fit(X_train, y_train)\n",
    "\n",
    "assert custom_pipe._fitted\n",
    "proba_custom = custom_pipe.predict_proba(X_test)[:, 1]\n",
    "custom_auc = calc_auc(y_test.values, proba_custom)\n",
    "print(f\"  Custom pipeline Test AUC: {custom_auc:.4f}\")\n",
    "assert custom_auc > 0.5\n",
    "print(\"Custom Pipeline ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. TimeSeriesSplitter\n",
    "\n",
    "Проверяем корректность time-based кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.utils.time_split import TimeSeriesSplitter\n",
    "\n",
    "with timer(\"14. TimeSeriesSplitter\"):\n",
    "    splitter = TimeSeriesSplitter(n_splits=5, time_col=\"date\", gap=0, expanding=True)\n",
    "    splits = list(splitter.split(X_train))\n",
    "\n",
    "print(f\"  Splits: {len(splits)}\")\n",
    "for i, (tr_idx, val_idx) in enumerate(splits):\n",
    "    tr_dates = X_train.iloc[tr_idx][\"date\"].unique()\n",
    "    val_dates = X_train.iloc[val_idx][\"date\"].unique()\n",
    "    # Проверяем: train dates < val dates\n",
    "    assert tr_dates.max() <= val_dates.min(), f\"Fold {i}: train dates overlap val dates\"\n",
    "    print(f\"  Fold {i}: train={len(tr_idx):,} ({len(tr_dates)} periods)  |  \"\n",
    "          f\"val={len(val_idx):,} ({len(val_dates)} periods)\")\n",
    "\n",
    "# Expanding: каждый следующий train должен быть >= предыдущего\n",
    "for i in range(1, len(splits)):\n",
    "    assert len(splits[i][0]) >= len(splits[i-1][0]), \"Expanding window нарушен\"\n",
    "\n",
    "print(\"TimeSeriesSplitter ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Synthetic Data Generator\n",
    "\n",
    "Проверяем  — генератор синтетических данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.utils.data_gen import make_scoring_dataset\n",
    "\n",
    "with timer(\"15. make_scoring_dataset (50K rows)\"):\n",
    "    df_synth = make_scoring_dataset(\n",
    "        n_samples=50_000, n_features=30, imbalance_ratio=10.0,\n",
    "        n_informative=10, n_time_periods=12, random_state=42,\n",
    "    )\n",
    "\n",
    "assert len(df_synth) == 50_000\n",
    "assert \"target\" in df_synth.columns\n",
    "assert \"date\" in df_synth.columns\n",
    "assert df_synth[\"target\"].nunique() == 2\n",
    "\n",
    "pos_rate = df_synth[\"target\"].mean()\n",
    "print(f\"  Shape: {df_synth.shape}\")\n",
    "print(f\"  Positive rate: {pos_rate:.3f} (expected ~{1/(1+10):.3f})\")\n",
    "print(f\"  NaN fraction: {df_synth.isna().mean().mean():.4f}\")\n",
    "print(f\"  Numeric cols: {df_synth.select_dtypes(include=[np.number]).shape[1]}\")\n",
    "print(f\"  Categorical cols: {df_synth.select_dtypes(include=['object']).shape[1]}\")\n",
    "print(f\"  Time periods: {df_synth['date'].nunique()}\")\n",
    "\n",
    "# Проверяем что информативные признаки создают сигнал\n",
    "from sklearn.metrics import roc_auc_score\n",
    "X_s = df_synth.drop(columns=[\"target\", \"date\"]).select_dtypes(include=[np.number]).fillna(0)\n",
    "y_s = df_synth[\"target\"]\n",
    "# Простая модель для проверки сигнала\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_check = LogisticRegression(max_iter=200, random_state=42)\n",
    "lr_check.fit(X_s, y_s)\n",
    "auc_check = roc_auc_score(y_s, lr_check.predict_proba(X_s)[:, 1])\n",
    "print(f\"  Sanity check AUC (LR on synthetic): {auc_check:.4f}\")\n",
    "assert auc_check > 0.55, \"Синтетические данные не содержат достаточно сигнала\"\n",
    "print(\"make_scoring_dataset ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Adversarial Validation\n",
    "\n",
    "Проверяем  — обнаружение covariate shift между train и holdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_refitting.boost_pipeline_steps import AdversarialValidation\n",
    "\n",
    "with timer(\"16. AdversarialValidation\"):\n",
    "    av = AdversarialValidation(auc_threshold=0.7, n_estimators=50)\n",
    "    av.fit(X_train, X_holdout=X_test)\n",
    "\n",
    "print(f\"  Adversarial AUC: {av.adversarial_auc_:.4f}\")\n",
    "print(f\"  Top drifted features: {av.feature_importances_.head(5).to_dict()}\")\n",
    "assert 0 <= av.adversarial_auc_ <= 1\n",
    "assert av.feature_importances_ is not None\n",
    "print(\"AdversarialValidation ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Сводная таблица по времени\n",
    "\n",
    "Итоговый отчёт по скорости выполнения всех модулей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 72)\n",
    "print(\"  СВОДНАЯ ТАБЛИЦА ЗАМЕРОВ ВРЕМЕНИ\")\n",
    "print(\"=\" * 72)\n",
    "print(f\"{' Этап':<55} {'Время (с)':>10}\")\n",
    "print(\"-\" * 72)\n",
    "\n",
    "total = 0\n",
    "for label, elapsed in TIMING.items():\n",
    "    total += elapsed\n",
    "    bar = \"█\" * int(min(elapsed / max(TIMING.values()) * 30, 30))\n",
    "    print(f\"  {label:<53} {elapsed:>8.2f}  {bar}\")\n",
    "\n",
    "print(\"-\" * 72)\n",
    "print(f\"  {'ИТОГО':<53} {total:>8.2f}\")\n",
    "print(\"=\" * 72)\n",
    "print()\n",
    "\n",
    "# Группировка по модулям\n",
    "groups = {}\n",
    "for label, elapsed in TIMING.items():\n",
    "    prefix = label.split(\".\")[0]\n",
    "    groups.setdefault(prefix, 0)\n",
    "    groups[prefix] += elapsed\n",
    "\n",
    "print(\"  ВРЕМЯ ПО МОДУЛЯМ:\")\n",
    "for g, t in sorted(groups.items(), key=lambda x: -x[1]):\n",
    "    pct = t / total * 100\n",
    "    print(f\"    {g:>4}: {t:>8.2f} s  ({pct:>5.1f}%)\")\n",
    "print()\n",
    "print(f\"Все {len(TIMING)} тестов пройдены успешно ✓\")"
   ]
  }
 ]
}